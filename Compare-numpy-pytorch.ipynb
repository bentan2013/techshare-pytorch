{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of numpy\n",
    "\n",
    "[Ref](https://github.com/jcjohnson/pytorch-examples#warm-up-numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = (y - y')^2\n",
    "grad = D(loss) = 2 * (y - y')\n",
    "\n",
    "From this part, we will know how to back prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34299101.1643\n",
      "1 29565503.9655\n",
      "2 27568741.3644\n",
      "3 23742808.9837\n",
      "4 18006019.3596\n",
      "5 11768393.693\n",
      "6 7123660.72201\n",
      "7 4214016.4084\n",
      "8 2623557.79083\n",
      "9 1761001.56484\n",
      "10 1280515.18105\n",
      "11 990929.350064\n",
      "12 801148.999889\n",
      "13 666675.734781\n",
      "14 565450.764787\n",
      "15 485693.540935\n",
      "16 420932.59177\n",
      "17 367243.724993\n",
      "18 322187.594216\n",
      "19 283971.504612\n",
      "20 251301.21809\n",
      "21 223171.458734\n",
      "22 198852.290592\n",
      "23 177697.030838\n",
      "24 159218.299999\n",
      "25 143009.708\n",
      "26 128756.788459\n",
      "27 116183.273273\n",
      "28 105053.773652\n",
      "29 95180.1233597\n",
      "30 86402.4069531\n",
      "31 78565.6974445\n",
      "32 71552.1289647\n",
      "33 65265.0073094\n",
      "34 59616.0709188\n",
      "35 54532.0029776\n",
      "36 49946.026287\n",
      "37 45807.1475574\n",
      "38 42062.0876179\n",
      "39 38666.2964944\n",
      "40 35584.2853616\n",
      "41 32782.0828264\n",
      "42 30231.4774025\n",
      "43 27907.9749146\n",
      "44 25787.6057519\n",
      "45 23852.6450449\n",
      "46 22082.832987\n",
      "47 20462.6055951\n",
      "48 18977.0471504\n",
      "49 17613.6788784\n",
      "50 16360.124457\n",
      "51 15207.2162411\n",
      "52 14145.1086254\n",
      "53 13165.8754219\n",
      "54 12263.1031313\n",
      "55 11429.9404792\n",
      "56 10659.6499393\n",
      "57 9947.31242726\n",
      "58 9287.87205449\n",
      "59 8677.07821408\n",
      "60 8111.16248518\n",
      "61 7585.73499367\n",
      "62 7097.93838886\n",
      "63 6644.74050939\n",
      "64 6223.41502034\n",
      "65 5831.51268637\n",
      "66 5466.74433624\n",
      "67 5127.10457437\n",
      "68 4810.46883894\n",
      "69 4515.27290077\n",
      "70 4239.88974654\n",
      "71 3982.8445448\n",
      "72 3742.64346641\n",
      "73 3518.21424111\n",
      "74 3308.45631405\n",
      "75 3112.2278359\n",
      "76 2928.88446551\n",
      "77 2757.24729706\n",
      "78 2596.47857313\n",
      "79 2445.84846877\n",
      "80 2304.66156893\n",
      "81 2172.26438674\n",
      "82 2048.01617381\n",
      "83 1931.35301816\n",
      "84 1821.84793945\n",
      "85 1719.03721693\n",
      "86 1622.52224435\n",
      "87 1531.76758\n",
      "88 1446.49521728\n",
      "89 1366.27860487\n",
      "90 1290.78287897\n",
      "91 1219.698681\n",
      "92 1152.79249909\n",
      "93 1089.7836087\n",
      "94 1030.41730351\n",
      "95 974.481533998\n",
      "96 921.771574755\n",
      "97 872.090447027\n",
      "98 825.241206224\n",
      "99 781.023301286\n",
      "100 739.29667773\n",
      "101 699.923475068\n",
      "102 662.76382624\n",
      "103 627.676851453\n",
      "104 594.547026491\n",
      "105 563.250042605\n",
      "106 533.675414911\n",
      "107 505.734704499\n",
      "108 479.332535144\n",
      "109 454.368621845\n",
      "110 430.748733897\n",
      "111 408.421905725\n",
      "112 387.302444676\n",
      "113 367.315372537\n",
      "114 348.408635718\n",
      "115 330.51288671\n",
      "116 313.573072757\n",
      "117 297.542866824\n",
      "118 282.376000938\n",
      "119 267.995804131\n",
      "120 254.375244173\n",
      "121 241.47301347\n",
      "122 229.255191257\n",
      "123 217.676990143\n",
      "124 206.703391764\n",
      "125 196.305567815\n",
      "126 186.444267192\n",
      "127 177.096952202\n",
      "128 168.238350849\n",
      "129 159.831688083\n",
      "130 151.859816874\n",
      "131 144.300734263\n",
      "132 137.128695296\n",
      "133 130.324556317\n",
      "134 123.867271016\n",
      "135 117.739886017\n",
      "136 111.924316273\n",
      "137 106.406343793\n",
      "138 101.171569461\n",
      "139 96.1977066287\n",
      "140 91.4739750566\n",
      "141 86.9889530777\n",
      "142 82.730165196\n",
      "143 78.685492419\n",
      "144 74.8450874196\n",
      "145 71.1971341781\n",
      "146 67.7303000129\n",
      "147 64.4367492566\n",
      "148 61.3086960193\n",
      "149 58.3346784176\n",
      "150 55.5091294729\n",
      "151 52.8248506918\n",
      "152 50.2720660738\n",
      "153 47.8457307042\n",
      "154 45.5394136794\n",
      "155 43.3467566461\n",
      "156 41.2621823066\n",
      "157 39.2808964383\n",
      "158 37.3963393211\n",
      "159 35.603685468\n",
      "160 33.8986218509\n",
      "161 32.2768798826\n",
      "162 30.7344878417\n",
      "163 29.2682728995\n",
      "164 27.8724085515\n",
      "165 26.5445438973\n",
      "166 25.2811556405\n",
      "167 24.0791176609\n",
      "168 22.9358401281\n",
      "169 21.84818605\n",
      "170 20.81259561\n",
      "171 19.826715475\n",
      "172 18.8883801791\n",
      "173 17.995357602\n",
      "174 17.1452968164\n",
      "175 16.3365448611\n",
      "176 15.5662647383\n",
      "177 14.8329150107\n",
      "178 14.1349136276\n",
      "179 13.4701932553\n",
      "180 12.8371092207\n",
      "181 12.2347061141\n",
      "182 11.6607146519\n",
      "183 11.1139747014\n",
      "184 10.5933686393\n",
      "185 10.0975273584\n",
      "186 9.62520750674\n",
      "187 9.17557184625\n",
      "188 8.74751674664\n",
      "189 8.33935297563\n",
      "190 7.950467796\n",
      "191 7.57996550017\n",
      "192 7.2270198163\n",
      "193 6.8908816275\n",
      "194 6.57055099581\n",
      "195 6.26521675877\n",
      "196 5.97426827741\n",
      "197 5.69700772276\n",
      "198 5.43290933445\n",
      "199 5.1812656917\n",
      "200 4.94137951857\n",
      "201 4.71267186771\n",
      "202 4.49468524379\n",
      "203 4.28690992332\n",
      "204 4.08892292526\n",
      "205 3.90019164637\n",
      "206 3.72024970775\n",
      "207 3.54875923375\n",
      "208 3.38522767727\n",
      "209 3.22934020141\n",
      "210 3.08075570996\n",
      "211 2.93904829913\n",
      "212 2.80391856722\n",
      "213 2.67509509753\n",
      "214 2.5522372432\n",
      "215 2.43508833783\n",
      "216 2.32343977678\n",
      "217 2.21690382467\n",
      "218 2.11534304816\n",
      "219 2.01850917163\n",
      "220 1.92609866428\n",
      "221 1.83799391232\n",
      "222 1.75397287991\n",
      "223 1.6737972623\n",
      "224 1.59732726653\n",
      "225 1.52439028492\n",
      "226 1.45483274414\n",
      "227 1.38848742542\n",
      "228 1.32518525369\n",
      "229 1.26480516181\n",
      "230 1.20718818716\n",
      "231 1.15222044502\n",
      "232 1.0997959433\n",
      "233 1.04978876579\n",
      "234 1.00205440098\n",
      "235 0.956511863043\n",
      "236 0.913055074552\n",
      "237 0.871591368346\n",
      "238 0.832040576329\n",
      "239 0.794310036892\n",
      "240 0.758289500833\n",
      "241 0.723911405873\n",
      "242 0.691111241851\n",
      "243 0.659806200219\n",
      "244 0.629943251812\n",
      "245 0.601439759746\n",
      "246 0.574240791162\n",
      "247 0.548271552785\n",
      "248 0.523486319878\n",
      "249 0.499835314198\n",
      "250 0.477269130167\n",
      "251 0.455721604595\n",
      "252 0.435150575401\n",
      "253 0.415515640851\n",
      "254 0.396772293246\n",
      "255 0.378888834792\n",
      "256 0.361813666095\n",
      "257 0.345512151426\n",
      "258 0.329950854954\n",
      "259 0.315093892885\n",
      "260 0.300915753573\n",
      "261 0.287381299524\n",
      "262 0.274455032657\n",
      "263 0.262114032142\n",
      "264 0.250333716365\n",
      "265 0.23908438322\n",
      "266 0.228347857603\n",
      "267 0.218096169255\n",
      "268 0.208305004261\n",
      "269 0.198955592809\n",
      "270 0.190031763282\n",
      "271 0.181509902152\n",
      "272 0.173374868119\n",
      "273 0.165606351776\n",
      "274 0.158185616314\n",
      "275 0.151099619368\n",
      "276 0.144333131567\n",
      "277 0.137873246368\n",
      "278 0.131703589106\n",
      "279 0.125810056531\n",
      "280 0.120182588461\n",
      "281 0.114808387367\n",
      "282 0.109675179011\n",
      "283 0.104776605833\n",
      "284 0.100094541696\n",
      "285 0.0956229585924\n",
      "286 0.0913527699322\n",
      "287 0.0872738071309\n",
      "288 0.0833788033529\n",
      "289 0.0796591791618\n",
      "290 0.0761055817357\n",
      "291 0.0727111793422\n",
      "292 0.0694684917513\n",
      "293 0.0663716607136\n",
      "294 0.0634146907773\n",
      "295 0.0605888389563\n",
      "296 0.057890136737\n",
      "297 0.0553116607681\n",
      "298 0.0528485569829\n",
      "299 0.0504967252431\n",
      "300 0.0482501543922\n",
      "301 0.0461033044005\n",
      "302 0.0440525531902\n",
      "303 0.0420932408355\n",
      "304 0.040221296764\n",
      "305 0.0384338291922\n",
      "306 0.036725434666\n",
      "307 0.0350933323652\n",
      "308 0.0335342509685\n",
      "309 0.0320446642741\n",
      "310 0.0306217528647\n",
      "311 0.0292626321535\n",
      "312 0.0279634315735\n",
      "313 0.0267222626751\n",
      "314 0.0255364051678\n",
      "315 0.0244035784627\n",
      "316 0.0233215007309\n",
      "317 0.0222871914358\n",
      "318 0.0212988722291\n",
      "319 0.020354583582\n",
      "320 0.0194523256671\n",
      "321 0.0185907029529\n",
      "322 0.0177671996966\n",
      "323 0.0169800983143\n",
      "324 0.0162279459193\n",
      "325 0.0155095108569\n",
      "326 0.0148228165957\n",
      "327 0.0141670052275\n",
      "328 0.0135400684828\n",
      "329 0.0129408051723\n",
      "330 0.0123681905674\n",
      "331 0.0118210784468\n",
      "332 0.0112983816314\n",
      "333 0.0107988372547\n",
      "334 0.0103213896361\n",
      "335 0.00986503404383\n",
      "336 0.00942894804724\n",
      "337 0.00901225329185\n",
      "338 0.00861416156657\n",
      "339 0.0082335629564\n",
      "340 0.00786985356952\n",
      "341 0.00752232671092\n",
      "342 0.00719010603169\n",
      "343 0.00687273421542\n",
      "344 0.00656933651839\n",
      "345 0.00627933324189\n",
      "346 0.00600217731278\n",
      "347 0.00573733164379\n",
      "348 0.00548423333618\n",
      "349 0.00524234883327\n",
      "350 0.00501118761087\n",
      "351 0.00479019844037\n",
      "352 0.00457897072872\n",
      "353 0.0043770916192\n",
      "354 0.00418418368778\n",
      "355 0.00399974046197\n",
      "356 0.00382343690807\n",
      "357 0.00365493430409\n",
      "358 0.00349388344527\n",
      "359 0.00333999293066\n",
      "360 0.00319289794651\n",
      "361 0.00305228430658\n",
      "362 0.00291785637078\n",
      "363 0.00278936329798\n",
      "364 0.00266653730466\n",
      "365 0.00254920317975\n",
      "366 0.00243699391891\n",
      "367 0.00232972230928\n",
      "368 0.00222719180164\n",
      "369 0.00212918894263\n",
      "370 0.00203552187885\n",
      "371 0.00194601453345\n",
      "372 0.00186042492142\n",
      "373 0.00177859136059\n",
      "374 0.00170038112557\n",
      "375 0.00162561763036\n",
      "376 0.00155416998529\n",
      "377 0.00148583890932\n",
      "378 0.0014205293834\n",
      "379 0.00135808534718\n",
      "380 0.00129839259467\n",
      "381 0.00124135545269\n",
      "382 0.00118682162895\n",
      "383 0.00113467408095\n",
      "384 0.00108482587744\n",
      "385 0.00103717342674\n",
      "386 0.00099161384126\n",
      "387 0.000948079942278\n",
      "388 0.000906443284367\n",
      "389 0.000866636852012\n",
      "390 0.000828588447133\n",
      "391 0.000792221560463\n",
      "392 0.00075745113949\n",
      "393 0.000724208872476\n",
      "394 0.000692420179533\n",
      "395 0.000662029589114\n",
      "396 0.000632977436934\n",
      "397 0.000605205035923\n",
      "398 0.000578664194113\n",
      "399 0.000553285105845\n",
      "400 0.000529015290498\n",
      "401 0.000505814197554\n",
      "402 0.000483628229327\n",
      "403 0.000462424228453\n",
      "404 0.000442151210278\n",
      "405 0.000422762895182\n",
      "406 0.000404225860686\n",
      "407 0.000386503724483\n",
      "408 0.000369559374139\n",
      "409 0.000353368339227\n",
      "410 0.000337882100775\n",
      "411 0.000323075833428\n",
      "412 0.000308916823474\n",
      "413 0.000295378708438\n",
      "414 0.000282439481916\n",
      "415 0.000270067720903\n",
      "416 0.000258237424636\n",
      "417 0.000246924100738\n",
      "418 0.000236107178527\n",
      "419 0.000225765479041\n",
      "420 0.000215881592978\n",
      "421 0.000206428354017\n",
      "422 0.000197389227019\n",
      "423 0.000188748685252\n",
      "424 0.000180484705002\n",
      "425 0.000172583657351\n",
      "426 0.000165030339684\n",
      "427 0.000157805711935\n",
      "428 0.000150898565614\n",
      "429 0.00014429426531\n",
      "430 0.000137978998281\n",
      "431 0.00013194306288\n",
      "432 0.000126169470709\n",
      "433 0.000120648153655\n",
      "434 0.00011536911354\n",
      "435 0.000110321824475\n",
      "436 0.000105495452331\n",
      "437 0.00010088176438\n",
      "438 9.64686465913e-05\n",
      "439 9.22487523871e-05\n",
      "440 8.82139811653e-05\n",
      "441 8.43565361564e-05\n",
      "442 8.06681663939e-05\n",
      "443 7.71409689814e-05\n",
      "444 7.37674960427e-05\n",
      "445 7.05419396145e-05\n",
      "446 6.74574142143e-05\n",
      "447 6.45084656084e-05\n",
      "448 6.16905472274e-05\n",
      "449 5.89937791637e-05\n",
      "450 5.64150794142e-05\n",
      "451 5.39491726363e-05\n",
      "452 5.15910180671e-05\n",
      "453 4.93366715306e-05\n",
      "454 4.71812340436e-05\n",
      "455 4.51193057659e-05\n",
      "456 4.31475484698e-05\n",
      "457 4.12623365813e-05\n",
      "458 3.94593236392e-05\n",
      "459 3.77357170045e-05\n",
      "460 3.60876008462e-05\n",
      "461 3.45110796502e-05\n",
      "462 3.30033561277e-05\n",
      "463 3.15615966703e-05\n",
      "464 3.01829644571e-05\n",
      "465 2.88650243594e-05\n",
      "466 2.76044240299e-05\n",
      "467 2.63988713834e-05\n",
      "468 2.52459124521e-05\n",
      "469 2.41433937137e-05\n",
      "470 2.30892431186e-05\n",
      "471 2.20814078308e-05\n",
      "472 2.11175024016e-05\n",
      "473 2.01956758167e-05\n",
      "474 1.9313923385e-05\n",
      "475 1.84707070542e-05\n",
      "476 1.76644805544e-05\n",
      "477 1.68935001584e-05\n",
      "478 1.61560773743e-05\n",
      "479 1.54508908247e-05\n",
      "480 1.47765350172e-05\n",
      "481 1.41315666418e-05\n",
      "482 1.35149903811e-05\n",
      "483 1.292520387e-05\n",
      "484 1.23611216868e-05\n",
      "485 1.18217833545e-05\n",
      "486 1.13058892694e-05\n",
      "487 1.08125269052e-05\n",
      "488 1.03409323069e-05\n",
      "489 9.88972724494e-06\n",
      "490 9.45826446112e-06\n",
      "491 9.04564217092e-06\n",
      "492 8.65103462075e-06\n",
      "493 8.27367308396e-06\n",
      "494 7.91286341557e-06\n",
      "495 7.56769063382e-06\n",
      "496 7.23768460829e-06\n",
      "497 6.92204921265e-06\n",
      "498 6.62014621399e-06\n",
      "499 6.33144921843e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    \n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code in file autograd/two_layer_net_autograd.py\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "  y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  print(t, loss.data[0])\n",
    "\n",
    "  loss.backward()\n",
    "    \n",
    "  w1.data -= learning_rate * w1.grad.data\n",
    "  w2.data -= learning_rate * w2.grad.data\n",
    "    \n",
    "  # Manually zero the gradients before running the backward pass\n",
    "  w1.grad.data.zero_()\n",
    "  w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}